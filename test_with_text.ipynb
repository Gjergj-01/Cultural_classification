{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fc69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandrococcia/Desktop/MNLP HW 1/Cultural_classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e0d052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "silverdataset = pd.read_csv('datasets/silver.csv')\n",
    "golddataset = pd.read_csv('datasets/gold.csv')\n",
    "\n",
    "text_silver = pd.read_csv('datasets/wikipedia_text_stats_grouped_silver_links.csv')\n",
    "text_gold = pd.read_csv('datasets/wikipedia_text_stats_grouped_gold_links.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbb7d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      entity              avg_bins  \\\n",
      "0  http://www.wikidata.org/entity/Q100309406  (1856.696, 3120.483]   \n",
      "\n",
      "             std_bins       len_bins  \n",
      "0  (-0.001, 1019.487]  (4.999, 24.0]  \n",
      "                                    entity                        avg_bins  \\\n",
      "0  http://www.wikidata.org/entity/Q1074069  (381.33200000000005, 2190.379]   \n",
      "\n",
      "             std_bins       len_bins  \n",
      "0  (-0.001, 1924.045]  (60.0, 159.5]  \n"
     ]
    }
   ],
   "source": [
    "# text_silver e text_gold preprocessing\n",
    "silver_text_dataset = pd.DataFrame(text_silver)\n",
    "silver_text_dataset = silver_text_dataset.drop(columns=[\"engtext\"])\n",
    "gold_text_dataset = pd.DataFrame(text_gold)\n",
    "gold_text_dataset = gold_text_dataset.drop(columns=[\"engtext\"])\n",
    "\n",
    "compute_len = lambda x: len(x)\n",
    "silver_text_dataset[\"len\"] = silver_text_dataset[\"distribution\"].apply(compute_len)\n",
    "gold_text_dataset[\"len\"] = gold_text_dataset[\"distribution\"].apply(compute_len)\n",
    "\n",
    "silver_text_dataset = silver_text_dataset.drop(columns=\"distribution\")\n",
    "gold_text_dataset = gold_text_dataset.drop(columns=\"distribution\")\n",
    "\n",
    "# avg, std, len are categorized based on quantili\n",
    "silver_text_dataset['avg_bins'] = pd.qcut(silver_text_dataset['avg'], q=4)  # 5 intervalli uguali\n",
    "silver_text_dataset['std_bins'] = pd.qcut(silver_text_dataset['std'], q=4)  # 5 intervalli uguali\n",
    "silver_text_dataset['len_bins'] = pd.qcut(silver_text_dataset['len'], q=4)  # 5 intervalli uguali\n",
    "\n",
    "gold_text_dataset['avg_bins'] = pd.qcut(gold_text_dataset['avg'], q=4)  # 5 intervalli uguali\n",
    "gold_text_dataset['std_bins'] = pd.qcut(gold_text_dataset['std'], q=4)  # 5 intervalli uguali\n",
    "gold_text_dataset['len_bins'] = pd.qcut(gold_text_dataset['len'], q=4)  # 5 intervalli uguali\n",
    "\n",
    "#avg, std, len are dropped\n",
    "silver_text_dataset = silver_text_dataset.drop(columns=[\"avg\", \"std\", \"len\"])\n",
    "gold_text_dataset = gold_text_dataset.drop(columns=[\"avg\", \"std\", \"len\"])\n",
    "\n",
    "print(silver_text_dataset.head(1))\n",
    "print(gold_text_dataset.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af5943d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item', 'name', 'description', 'type', 'category', 'subcategory',\n",
      "       'label', 'avg_bins', 'std_bins', 'len_bins'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Now we want to combine [silverdataset, silver_text_dataset] and [goldataset, gold_text_dataset] with respect to the key <entity>\n",
    "silver_merged = pd.merge(silverdataset, silver_text_dataset, left_on='item', right_on='entity')\n",
    "gold_merged = pd.merge(golddataset, gold_text_dataset, left_on='item', right_on='entity')\n",
    "\n",
    "silver_merged = silver_merged.drop(columns=\"entity\")\n",
    "gold_merged = gold_merged.drop(columns=\"entity\")\n",
    "print(silver_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9d7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = silver_merged\n",
    "evaluation_data = gold_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08c80e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_from_text(column):\n",
    "    nations = set(pd.read_csv('datasets/national_adjectives.csv')[\"Country\"])\n",
    "    national_adjectives = set(pd.read_csv('datasets/national_adjectives.csv')[\"Adjective\"])\n",
    "    \n",
    "    column['new_description'] = column.apply(lambda elem: set(elem.iloc[0].split()), axis=1)\n",
    "    column['length_description_intersection'] = column['new_description'].apply(lambda elem:  len(elem.intersection(national_adjectives)))\n",
    "    \n",
    "    column['nations'] = column['new_description'].apply(lambda elem:  len(elem.intersection(nations)))\n",
    "\n",
    "    return column['length_description_intersection'], column['nations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "200f0f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['avg_bins', 'std_bins', 'len_bins'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# One-hot encoding\u001b[39;00m\n\u001b[32m     17\u001b[39m encoder = OneHotEncoder(sparse_output=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m encoded_features = encoder.fit_transform(pd.concat([\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m]\u001b[49m, evaluation_dataset[categorical_columns]]))\n\u001b[32m     19\u001b[39m encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Pulizia e unione nel dataset di training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MNLP HW 1/Cultural_classification/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MNLP HW 1/Cultural_classification/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MNLP HW 1/Cultural_classification/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['avg_bins', 'std_bins', 'len_bins'] not in index\""
     ]
    }
   ],
   "source": [
    "# Rimuovo colonne non utili dal training set e dall'evaluation test\n",
    "dataset = training_data.drop(columns=[\"item\", \"name\", \"description\"])\n",
    "evaluation_dataset = evaluation_data.drop(columns=[\"item\", \"name\", \"description\"])\n",
    "\n",
    "# Heuristic su 'description'\n",
    "train_desc = pd.DataFrame(training_data[\"description\"])\n",
    "dataset['h_description'], dataset['nations'] = heuristic_from_text(train_desc)\n",
    "\n",
    "# Stesso preprocessing per l'evaluation set\n",
    "eval_desc = pd.DataFrame(evaluation_data[\"description\"])\n",
    "evaluation_dataset['h_description'], evaluation_dataset['nations'] = heuristic_from_text(eval_desc)\n",
    "\n",
    "# Colonne categoriali da codificare\n",
    "categorical_columns = [\"h_description\", \"nations\", \"type\", \"category\", \"subcategory\", \"label\", \"avg_bins\", \"std_bins\", \"len_bins\"]\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(pd.concat([dataset[categorical_columns], evaluation_dataset[categorical_columns]]))\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Pulizia e unione nel dataset di training\n",
    "dataset = dataset.drop(columns=categorical_columns)\n",
    "dataset = pd.concat([dataset, encoded_df], axis=1)\n",
    "\n",
    "# Applico lo stesso encoder all'evaluation set\n",
    "encoded_eval = encoder.transform(evaluation_dataset[categorical_columns])\n",
    "encoded_eval_df = pd.DataFrame(encoded_eval, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "evaluation_dataset = evaluation_dataset.drop(columns=categorical_columns)\n",
    "evaluation_dataset = pd.concat([evaluation_dataset, encoded_eval_df], axis=1)\n",
    "\n",
    "# Seleziono feature e target\n",
    "labels = ['label_cultural agnostic', 'label_cultural exclusive', 'label_cultural representative']\n",
    "X_train = dataset.drop(columns=labels)\n",
    "y_train = dataset[labels]\n",
    "X_test = evaluation_dataset.drop(columns=labels)\n",
    "y_test = evaluation_dataset[labels]\n",
    "\n",
    "# Random Forest training\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predizioni sul test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuratezza\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuratezza del modello: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
